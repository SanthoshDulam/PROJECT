{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"a48fbb9e928040b994adbab6cbd31636":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2229074d8d88414b90bb7880de581985","IPY_MODEL_19a9c31a06a342a49731f8b4bc94f2ab","IPY_MODEL_30aadb6b21f446a9aac621a313dc757e"],"layout":"IPY_MODEL_54d6ff85408040d385b0d9229bfe621d"}},"2229074d8d88414b90bb7880de581985":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_471b2526b14a4d1a91d0f1154b54438b","placeholder":"​","style":"IPY_MODEL_a97c44e8518c4989b6b2b121e5a9f5a2","value":"config.json: 100%"}},"19a9c31a06a342a49731f8b4bc94f2ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb3b2227e6bc48e9b71d6c4fec4789d9","max":625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_06602b5000f54d7182f69b361bb47685","value":625}},"30aadb6b21f446a9aac621a313dc757e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0148fc457e1e4bb5ac3d67372222a3e9","placeholder":"​","style":"IPY_MODEL_1d4259addf6848728d884a1af73ae78a","value":" 625/625 [00:00&lt;00:00, 20.4kB/s]"}},"54d6ff85408040d385b0d9229bfe621d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"471b2526b14a4d1a91d0f1154b54438b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a97c44e8518c4989b6b2b121e5a9f5a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb3b2227e6bc48e9b71d6c4fec4789d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06602b5000f54d7182f69b361bb47685":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0148fc457e1e4bb5ac3d67372222a3e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d4259addf6848728d884a1af73ae78a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b4d598bccf44ad4a14ba70232602bb9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_429cf20ddaac4e49bb874def3f9aa798","IPY_MODEL_4a1c3a1d979244208407479a3335000f","IPY_MODEL_b4219deb12c54e26a456dd6f5d903175"],"layout":"IPY_MODEL_7100a474527745838faf054df61afae3"}},"429cf20ddaac4e49bb874def3f9aa798":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45e9ac3767164a8b91344c9512eb6315","placeholder":"​","style":"IPY_MODEL_955dab9a062643df82ce3baf44f67485","value":"model.safetensors: 100%"}},"4a1c3a1d979244208407479a3335000f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4f018360b1b4dbdb51b3b1b090a5abb","max":714290682,"min":0,"orientation":"horizontal","style":"IPY_MODEL_04774ec3c8c341199126fa4338e90d62","value":714290682}},"b4219deb12c54e26a456dd6f5d903175":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd6d3ef6ad234d0b98242dc59f4928fe","placeholder":"​","style":"IPY_MODEL_9944f5cf69ef45edb088cd78cdab096b","value":" 714M/714M [00:03&lt;00:00, 207MB/s]"}},"7100a474527745838faf054df61afae3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45e9ac3767164a8b91344c9512eb6315":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"955dab9a062643df82ce3baf44f67485":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4f018360b1b4dbdb51b3b1b090a5abb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04774ec3c8c341199126fa4338e90d62":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd6d3ef6ad234d0b98242dc59f4928fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9944f5cf69ef45edb088cd78cdab096b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86a00ef8f226464283c4bc1137052942":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33f03bd79619422bb2ee1fe3c69621c4","IPY_MODEL_645320d75d0e4f7099066699a87c2053","IPY_MODEL_cc9c0520b3e744f5b59c4ac66f8adf0e"],"layout":"IPY_MODEL_fb373dbf1bff4b168ca55cc35e7dc0d2"}},"33f03bd79619422bb2ee1fe3c69621c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22cf41115e264094be37dfef06af2ca3","placeholder":"​","style":"IPY_MODEL_f01a1f76e8ea4ca7ab449e00c9b91ef4","value":"tokenizer_config.json: 100%"}},"645320d75d0e4f7099066699a87c2053":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea80ae66d2404d90baabe8b16425b3dc","max":49,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f75129682b7d441f97703b55095ea504","value":49}},"cc9c0520b3e744f5b59c4ac66f8adf0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12cc163c18db435589e872af6b48a01f","placeholder":"​","style":"IPY_MODEL_e2c49f6c654e424e879f7f10d67283ad","value":" 49.0/49.0 [00:00&lt;00:00, 3.20kB/s]"}},"fb373dbf1bff4b168ca55cc35e7dc0d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22cf41115e264094be37dfef06af2ca3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f01a1f76e8ea4ca7ab449e00c9b91ef4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea80ae66d2404d90baabe8b16425b3dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f75129682b7d441f97703b55095ea504":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"12cc163c18db435589e872af6b48a01f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2c49f6c654e424e879f7f10d67283ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cda77a08ef644b78a73f3eb496e02d08":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4382e8c575f848148967cb936d4a0f5b","IPY_MODEL_ec80eda8d9fa402ea03e6d4696c8792a","IPY_MODEL_c801053602ac4c1abb48dacb1a82e407"],"layout":"IPY_MODEL_5caeb32f402b4896a52f086602b554df"}},"4382e8c575f848148967cb936d4a0f5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_925e1131cbe3498d85de77ca06de9e18","placeholder":"​","style":"IPY_MODEL_cc78325a068d495499c5b1d4a7f955d4","value":"vocab.txt: 100%"}},"ec80eda8d9fa402ea03e6d4696c8792a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3db7ccc120104b048aef175e29545bd9","max":995526,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f562ab0d8809447b8ae132bdebf6cd06","value":995526}},"c801053602ac4c1abb48dacb1a82e407":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a910402a2f06451ebf5cf3efca82c142","placeholder":"​","style":"IPY_MODEL_7b7654002d774597bec889b60f518048","value":" 996k/996k [00:00&lt;00:00, 7.02MB/s]"}},"5caeb32f402b4896a52f086602b554df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"925e1131cbe3498d85de77ca06de9e18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc78325a068d495499c5b1d4a7f955d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3db7ccc120104b048aef175e29545bd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f562ab0d8809447b8ae132bdebf6cd06":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a910402a2f06451ebf5cf3efca82c142":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b7654002d774597bec889b60f518048":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1859b2dd3ac34383a534a32cadd2e264":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_298e0f47b5f44d4fafd0e11c5d48a50d","IPY_MODEL_6064361b06a941c483d050d688fb4bda","IPY_MODEL_e03ec9a071744397943f2ab259e08937"],"layout":"IPY_MODEL_b75be0361a70470284880526cc0192d6"}},"298e0f47b5f44d4fafd0e11c5d48a50d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3e7c1d104f04204a3f25c2882d8b3d0","placeholder":"​","style":"IPY_MODEL_d18986850f7c4e64a4660b2b828afd76","value":"tokenizer.json: 100%"}},"6064361b06a941c483d050d688fb4bda":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_20a42020664e4e9a841774fb6d977798","max":1961828,"min":0,"orientation":"horizontal","style":"IPY_MODEL_49f6f29488c8480fa405bebda13f6364","value":1961828}},"e03ec9a071744397943f2ab259e08937":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9458a8e8bc74ad38f4a9ed83cc20ce9","placeholder":"​","style":"IPY_MODEL_53204a52da4640fc89ca07f72c34f960","value":" 1.96M/1.96M [00:00&lt;00:00, 25.3MB/s]"}},"b75be0361a70470284880526cc0192d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3e7c1d104f04204a3f25c2882d8b3d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d18986850f7c4e64a4660b2b828afd76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20a42020664e4e9a841774fb6d977798":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49f6f29488c8480fa405bebda13f6364":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b9458a8e8bc74ad38f4a9ed83cc20ce9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53204a52da4640fc89ca07f72c34f960":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9721394,"sourceType":"datasetVersion","datasetId":5947848}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Pre Processing**","metadata":{}},{"cell_type":"code","source":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:16:42.343816Z","iopub.execute_input":"2024-10-30T08:16:42.344115Z","iopub.status.idle":"2024-10-30T08:16:42.348893Z","shell.execute_reply.started":"2024-10-30T08:16:42.344082Z","shell.execute_reply":"2024-10-30T08:16:42.347736Z"},"trusted":true},"outputs":[],"execution_count":113},{"cell_type":"code","source":"nltk.download('punkt')\nnltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:16:42.350223Z","iopub.execute_input":"2024-10-30T08:16:42.350572Z","iopub.status.idle":"2024-10-30T08:16:42.362105Z","shell.execute_reply.started":"2024-10-30T08:16:42.350538Z","shell.execute_reply":"2024-10-30T08:16:42.361258Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":114},{"cell_type":"code","source":"#telugu stop words\ntelugu_stopwords = set([\n    \"అందుకే\", \"ఎప్పుడు\", \"ఎక్కడ\", \"ఎవరూ\", \"ఎవరు\", \"ఎవరిది\", \"ఎలా\", \n    \"ఏ\", \"ఏది\", \"ఏడు\", \"కాదు\", \"కూడా\", \"తప్పుడు\", \"తరువాత\", \n    \"తర్వాత\", \"మరి\", \"మాత్రమే\", \"ముందు\", \"వీరు\", \"వెంటనే\", \"ఇంకా\",\n    \"ఇది\", \"అది\", \"ఎప్పుడు\", \"నేను\", \"మీ\", \"మీరు\", \"అలాగే\", \"ముందుగా\"\n])\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:16:42.363579Z","iopub.execute_input":"2024-10-30T08:16:42.364322Z","iopub.status.idle":"2024-10-30T08:16:42.371662Z","shell.execute_reply.started":"2024-10-30T08:16:42.364285Z","shell.execute_reply":"2024-10-30T08:16:42.370793Z"},"trusted":true},"outputs":[],"execution_count":115},{"cell_type":"code","source":"# Function for text preprocessing\ndef preprocess_text(text):\n    # Remove punctuations and special characters\n    text = re.sub(r'[^\\w\\s]', '', text)\n    \n    # Convert to lowercase\n    text = text.lower()\n    \n    # Tokenize the text\n    tokens = word_tokenize(text)\n    \n    # Remove stopwords\n    tokens = [word for word in tokens if word not in telugu_stopwords]\n    \n    return ' '.join(tokens)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:16:42.372848Z","iopub.execute_input":"2024-10-30T08:16:42.373117Z","iopub.status.idle":"2024-10-30T08:16:42.385084Z","shell.execute_reply.started":"2024-10-30T08:16:42.373087Z","shell.execute_reply":"2024-10-30T08:16:42.384241Z"},"trusted":true},"outputs":[],"execution_count":116},{"cell_type":"code","source":"df = pd.read_excel('/kaggle/input/dataset1/TELUGU_METADATA.xlsx')\n","metadata":{"id":"jjLJotOnDJCG","execution":{"iopub.status.busy":"2024-10-30T08:16:42.386011Z","iopub.execute_input":"2024-10-30T08:16:42.386295Z","iopub.status.idle":"2024-10-30T08:16:42.543703Z","shell.execute_reply.started":"2024-10-30T08:16:42.386264Z","shell.execute_reply":"2024-10-30T08:16:42.543001Z"},"trusted":true},"outputs":[],"execution_count":117},{"cell_type":"code","source":"# Binary classification based on 'AUDIO FILE NAME'\ndf['BINARY_LABEL'] = df['AUDIO FILE NAME'].apply(lambda x: 'H' if x.startswith('H') else 'NH')\n\n# Print counts for each class\nprint(\"Binary Label Counts:\")\nprint(df['BINARY_LABEL'].value_counts())\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sFDoWZq8DV6p","outputId":"9fb20a26-93f8-473f-9ec8-04f45c82336e","execution":{"iopub.status.busy":"2024-10-30T08:16:42.544623Z","iopub.execute_input":"2024-10-30T08:16:42.544895Z","iopub.status.idle":"2024-10-30T08:16:42.552064Z","shell.execute_reply.started":"2024-10-30T08:16:42.544865Z","shell.execute_reply":"2024-10-30T08:16:42.551183Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Binary Label Counts:\nBINARY_LABEL\nH     392\nNH    209\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":118},{"cell_type":"code","source":"# Apply preprocessing\ndf['processed_text'] = df['TRANSCRIPTION'].apply(preprocess_text)\n\nprint(df[['TRANSCRIPTION', 'processed_text']].head())","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:16:42.553348Z","iopub.execute_input":"2024-10-30T08:16:42.553720Z","iopub.status.idle":"2024-10-30T08:16:42.725943Z","shell.execute_reply.started":"2024-10-30T08:16:42.553678Z","shell.execute_reply":"2024-10-30T08:16:42.725045Z"},"trusted":true},"outputs":[{"name":"stdout","text":"                                       TRANSCRIPTION  \\\n0               ఎస్సీలుగా పుట్టాలని ఎవరు కోరుకుంటారు   \n1  ఎవరు మాత్రం SC కులంలో పుట్టాలని కోరుకుంటారు అం...   \n2        ఎవరు మాత్రం SC కులంలో పుట్టాలని కోరుకుంటారు   \n3  ఎవరు మాత్రం SC కులంలో పుట్టాలని కోరుకుంటారు డబ...   \n4  అందరూ రాజుల కులంలో పుడితే రాజ్యాన్ని ఎలచ్చనుకు...   \n\n                                      processed_text  \n0                              ఎససలగ పటటలన ఎవర కరకటర  \n1  ఎవర మతర sc కలల పటటలన కరకటర అదర సపనన వరగలలన పటట...  \n2                         ఎవర మతర sc కలల పటటలన కరకటర  \n3  ఎవర మతర sc కలల పటటలన కరకటర డబబల లకపత అదర సపనన ...  \n4                     అదర రజల కలల పడత రజయనన ఎలచచనకటర  \n","output_type":"stream"}],"execution_count":119},{"cell_type":"markdown","source":"##  **NGRAM**","metadata":{}},{"cell_type":"code","source":"import random\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Define the vectorizer for unigrams, bigrams, and trigrams\nvectorizer = CountVectorizer(ngram_range=(1, 3))\nX = vectorizer.fit_transform(df['processed_text'])\n\n# Get the n-gram features (vocabulary)\nn_gram_features = vectorizer.get_feature_names_out()\n\n# Get the total number of unique n-grams\ntotal_unique_ngrams = len(n_gram_features)\n\n# Print the total count of unique n-grams (vocabulary size)\nprint(f\"Total unique n-grams (vocabulary size): {total_unique_ngrams}\")\n\n# Select 10 random n-grams from the vocabulary\nrandom_ngrams = random.sample(list(n_gram_features), 10)\n\n# Print the 10 random n-grams\nprint(\"Random sample of 10 n-grams:\")\nfor ngram in random_ngrams:\n    print(ngram)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:16:42.726945Z","iopub.execute_input":"2024-10-30T08:16:42.727250Z","iopub.status.idle":"2024-10-30T08:16:42.853001Z","shell.execute_reply.started":"2024-10-30T08:16:42.727219Z","shell.execute_reply":"2024-10-30T08:16:42.852165Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Total unique n-grams (vocabulary size): 28832\nRandom sample of 10 n-grams:\nటవ సనమల నషధ\nపరమల మరచన\nతవరగ చపతననవ\nకన వనయ గపపద\nనటసత గరలఫరడ దగతడ\nసతర ఉనన\nఅనక నన\nమర పటచకర\nమద మణల వచచన\nకటరకట పయన ఉట\n","output_type":"stream"}],"execution_count":120},{"cell_type":"markdown","source":"## **Bag of Words**","metadata":{}},{"cell_type":"code","source":"# Check if there are any empty processed_text rows\nempty_rows = df['processed_text'].apply(lambda x: len(x.strip()) == 0).sum()\n\nprint(f\"Number of empty rows after preprocessing: {empty_rows}\")\n\n# Check the first few rows of processed_text to verify proper preprocessing\nprint(df['processed_text'].head())\n\n# If everything looks good, use CountVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nbow_vectorizer = CountVectorizer()\n\n# Fit the vectorizer and transform the text data\nbow_matrix = bow_vectorizer.fit_transform(df['processed_text'])\n\n# If the matrix still has zeros, print the sum of each row\nprint(bow_matrix.toarray())\n\n# Display any row sums that are 0 (meaning no words were found in that document)\nrow_sums = bow_matrix.toarray().sum(axis=1)\nprint(f\"Rows with zero sum (no words found): {sum(row_sums == 0)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:16:42.853979Z","iopub.execute_input":"2024-10-30T08:16:42.854236Z","iopub.status.idle":"2024-10-30T08:16:42.900290Z","shell.execute_reply.started":"2024-10-30T08:16:42.854207Z","shell.execute_reply":"2024-10-30T08:16:42.899360Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Number of empty rows after preprocessing: 0\n0                                ఎససలగ పటటలన ఎవర కరకటర\n1    ఎవర మతర sc కలల పటటలన కరకటర అదర సపనన వరగలలన పటట...\n2                           ఎవర మతర sc కలల పటటలన కరకటర\n3    ఎవర మతర sc కలల పటటలన కరకటర డబబల లకపత అదర సపనన ...\n4                       అదర రజల కలల పడత రజయనన ఎలచచనకటర\nName: processed_text, dtype: object\n[[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\nRows with zero sum (no words found): 0\n","output_type":"stream"}],"execution_count":121},{"cell_type":"markdown","source":"## **Word Tokenization**","metadata":{}},{"cell_type":"code","source":"# Tokenization using NLTK\ndf['tokenized_text'] = df['processed_text'].apply(word_tokenize)\n\nprint(df[['processed_text', 'tokenized_text']].head())\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:16:42.901411Z","iopub.execute_input":"2024-10-30T08:16:42.901731Z","iopub.status.idle":"2024-10-30T08:16:43.042316Z","shell.execute_reply.started":"2024-10-30T08:16:42.901693Z","shell.execute_reply":"2024-10-30T08:16:43.041377Z"},"trusted":true},"outputs":[{"name":"stdout","text":"                                      processed_text  \\\n0                              ఎససలగ పటటలన ఎవర కరకటర   \n1  ఎవర మతర sc కలల పటటలన కరకటర అదర సపనన వరగలలన పటట...   \n2                         ఎవర మతర sc కలల పటటలన కరకటర   \n3  ఎవర మతర sc కలల పటటలన కరకటర డబబల లకపత అదర సపనన ...   \n4                     అదర రజల కలల పడత రజయనన ఎలచచనకటర   \n\n                                      tokenized_text  \n0                         [ఎససలగ, పటటలన, ఎవర, కరకటర]  \n1  [ఎవర, మతర, sc, కలల, పటటలన, కరకటర, అదర, సపనన, వ...  \n2                  [ఎవర, మతర, sc, కలల, పటటలన, కరకటర]  \n3  [ఎవర, మతర, sc, కలల, పటటలన, కరకటర, డబబల, లకపత, ...  \n4              [అదర, రజల, కలల, పడత, రజయనన, ఎలచచనకటర]  \n","output_type":"stream"}],"execution_count":122},{"cell_type":"markdown","source":"## **FOR BINARY CLASSIFICATION(M-BERT)**","metadata":{"id":"4oD9WNShDlzL"}},{"cell_type":"code","source":"# Import necessary libraries\nimport torch\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\n","metadata":{"id":"55Rb5BdWDIYm","execution":{"iopub.status.busy":"2024-10-30T08:16:43.043484Z","iopub.execute_input":"2024-10-30T08:16:43.043825Z","iopub.status.idle":"2024-10-30T08:16:43.050161Z","shell.execute_reply.started":"2024-10-30T08:16:43.043790Z","shell.execute_reply":"2024-10-30T08:16:43.049350Z"},"trusted":true},"outputs":[],"execution_count":123},{"cell_type":"code","source":"from transformers import BertForSequenceClassification\n\n# Define the model with 5 labels (Non-hate + 4 hate categories)\nmodel = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=5)\ntokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":370,"referenced_widgets":["a48fbb9e928040b994adbab6cbd31636","2229074d8d88414b90bb7880de581985","19a9c31a06a342a49731f8b4bc94f2ab","30aadb6b21f446a9aac621a313dc757e","54d6ff85408040d385b0d9229bfe621d","471b2526b14a4d1a91d0f1154b54438b","a97c44e8518c4989b6b2b121e5a9f5a2","fb3b2227e6bc48e9b71d6c4fec4789d9","06602b5000f54d7182f69b361bb47685","0148fc457e1e4bb5ac3d67372222a3e9","1d4259addf6848728d884a1af73ae78a","8b4d598bccf44ad4a14ba70232602bb9","429cf20ddaac4e49bb874def3f9aa798","4a1c3a1d979244208407479a3335000f","b4219deb12c54e26a456dd6f5d903175","7100a474527745838faf054df61afae3","45e9ac3767164a8b91344c9512eb6315","955dab9a062643df82ce3baf44f67485","e4f018360b1b4dbdb51b3b1b090a5abb","04774ec3c8c341199126fa4338e90d62","dd6d3ef6ad234d0b98242dc59f4928fe","9944f5cf69ef45edb088cd78cdab096b","86a00ef8f226464283c4bc1137052942","33f03bd79619422bb2ee1fe3c69621c4","645320d75d0e4f7099066699a87c2053","cc9c0520b3e744f5b59c4ac66f8adf0e","fb373dbf1bff4b168ca55cc35e7dc0d2","22cf41115e264094be37dfef06af2ca3","f01a1f76e8ea4ca7ab449e00c9b91ef4","ea80ae66d2404d90baabe8b16425b3dc","f75129682b7d441f97703b55095ea504","12cc163c18db435589e872af6b48a01f","e2c49f6c654e424e879f7f10d67283ad","cda77a08ef644b78a73f3eb496e02d08","4382e8c575f848148967cb936d4a0f5b","ec80eda8d9fa402ea03e6d4696c8792a","c801053602ac4c1abb48dacb1a82e407","5caeb32f402b4896a52f086602b554df","925e1131cbe3498d85de77ca06de9e18","cc78325a068d495499c5b1d4a7f955d4","3db7ccc120104b048aef175e29545bd9","f562ab0d8809447b8ae132bdebf6cd06","a910402a2f06451ebf5cf3efca82c142","7b7654002d774597bec889b60f518048","1859b2dd3ac34383a534a32cadd2e264","298e0f47b5f44d4fafd0e11c5d48a50d","6064361b06a941c483d050d688fb4bda","e03ec9a071744397943f2ab259e08937","b75be0361a70470284880526cc0192d6","f3e7c1d104f04204a3f25c2882d8b3d0","d18986850f7c4e64a4660b2b828afd76","20a42020664e4e9a841774fb6d977798","49f6f29488c8480fa405bebda13f6364","b9458a8e8bc74ad38f4a9ed83cc20ce9","53204a52da4640fc89ca07f72c34f960"]},"id":"DkbVfAn4Da1e","outputId":"7efa396f-5176-4b27-f430-42d60611c988","execution":{"iopub.status.busy":"2024-10-30T08:16:43.051572Z","iopub.execute_input":"2024-10-30T08:16:43.051969Z","iopub.status.idle":"2024-10-30T08:16:43.665353Z","shell.execute_reply.started":"2024-10-30T08:16:43.051928Z","shell.execute_reply":"2024-10-30T08:16:43.664528Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":124},{"cell_type":"code","source":"class HateSpeechDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len, binary=False):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.binary = binary  # Flag to indicate binary or multi-class\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n\n        # Tokenization\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        # Label: For binary, 'NH' as 0, 'H' as 1. Multi-class uses label mapping\n        label_value = torch.tensor(1 if label == 'H' else 0, dtype=torch.long) if self.binary else torch.tensor(label, dtype=torch.long)\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': label_value\n        }\n","metadata":{"id":"DlnPte6bDXPK","execution":{"iopub.status.busy":"2024-10-30T08:16:43.666764Z","iopub.execute_input":"2024-10-30T08:16:43.667465Z","iopub.status.idle":"2024-10-30T08:16:43.676507Z","shell.execute_reply.started":"2024-10-30T08:16:43.667417Z","shell.execute_reply":"2024-10-30T08:16:43.675543Z"},"trusted":true},"outputs":[],"execution_count":125},{"cell_type":"code","source":"# Set up device for GPU if available, else use CPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","metadata":{"id":"mgpSz6XBDZNq","execution":{"iopub.status.busy":"2024-10-30T08:16:43.677629Z","iopub.execute_input":"2024-10-30T08:16:43.677909Z","iopub.status.idle":"2024-10-30T08:16:43.687068Z","shell.execute_reply.started":"2024-10-30T08:16:43.677879Z","shell.execute_reply":"2024-10-30T08:16:43.686148Z"},"trusted":true},"outputs":[],"execution_count":126},{"cell_type":"code","source":"# Binary classification model setup with two labels (Hate vs. Non-Hate)\nbinary_model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\nbinary_model = binary_model.to(device)\nbinary_optimizer = torch.optim.AdamW(binary_model.parameters(), lr=1e-5)\n\n# Split dataset for binary classification\nbinary_train_texts, binary_test_texts, binary_train_labels, binary_test_labels = train_test_split(df['TRANSCRIPTION'], df['BINARY_LABEL'], test_size=0.2)\n\n# Binary Dataset and DataLoader\nbinary_train_dataset = HateSpeechDataset(binary_train_texts.tolist(), binary_train_labels.tolist(), tokenizer, max_len=128, binary=True)\nbinary_test_dataset = HateSpeechDataset(binary_test_texts.tolist(), binary_test_labels.tolist(), tokenizer, max_len=128, binary=True)\n\nbinary_train_loader = DataLoader(binary_train_dataset, batch_size=16, shuffle=True)\nbinary_test_loader = DataLoader(binary_test_dataset, batch_size=16)\n\n# Binary Classification Training Loop\nfor epoch in range(25):  # You can adjust the number of epochs\n    binary_model.train()\n    for batch in binary_train_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        binary_optimizer.zero_grad()\n        outputs = binary_model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        binary_optimizer.step()\n\n    print(f\"Binary Classification Epoch {epoch + 1} finished\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ZWSbnUjDfRf","outputId":"ce084888-5236-47ce-f040-b2477eeb71db","execution":{"iopub.status.busy":"2024-10-30T08:16:43.688248Z","iopub.execute_input":"2024-10-30T08:16:43.688875Z","iopub.status.idle":"2024-10-30T08:19:14.988148Z","shell.execute_reply.started":"2024-10-30T08:16:43.688832Z","shell.execute_reply":"2024-10-30T08:19:14.986909Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Binary Classification Epoch 1 finished\nBinary Classification Epoch 2 finished\nBinary Classification Epoch 3 finished\nBinary Classification Epoch 4 finished\nBinary Classification Epoch 5 finished\nBinary Classification Epoch 6 finished\nBinary Classification Epoch 7 finished\nBinary Classification Epoch 8 finished\nBinary Classification Epoch 9 finished\nBinary Classification Epoch 10 finished\nBinary Classification Epoch 11 finished\nBinary Classification Epoch 12 finished\nBinary Classification Epoch 13 finished\nBinary Classification Epoch 14 finished\nBinary Classification Epoch 15 finished\nBinary Classification Epoch 16 finished\nBinary Classification Epoch 17 finished\nBinary Classification Epoch 18 finished\nBinary Classification Epoch 19 finished\nBinary Classification Epoch 20 finished\nBinary Classification Epoch 21 finished\nBinary Classification Epoch 22 finished\nBinary Classification Epoch 23 finished\nBinary Classification Epoch 24 finished\nBinary Classification Epoch 25 finished\n","output_type":"stream"}],"execution_count":127},{"cell_type":"code","source":"# Testing Binary Classification Model\nbinary_test_preds = []\nbinary_test_labels_eval = []\n\nbinary_model.eval()\nwith torch.no_grad():\n    for batch in binary_test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        outputs = binary_model(input_ids, attention_mask=attention_mask)\n        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n        binary_test_preds.extend(preds)\n        binary_test_labels_eval.extend(labels.cpu().numpy())\n\n# Evaluate binary accuracy\nbinary_accuracy = accuracy_score(binary_test_labels_eval, binary_test_preds)\nprint(f\"Binary Classification Accuracy: {binary_accuracy}\")\nprint(classification_report(binary_test_labels_eval, binary_test_preds, target_names=['Non-Hate', 'Hate']))\n","metadata":{"id":"5A3B5cXGDjyD","execution":{"iopub.status.busy":"2024-10-30T08:19:14.989479Z","iopub.execute_input":"2024-10-30T08:19:14.989804Z","iopub.status.idle":"2024-10-30T08:19:15.710267Z","shell.execute_reply.started":"2024-10-30T08:19:14.989769Z","shell.execute_reply":"2024-10-30T08:19:15.709303Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Binary Classification Accuracy: 0.8512396694214877\n              precision    recall  f1-score   support\n\n    Non-Hate       0.72      0.80      0.76        35\n        Hate       0.91      0.87      0.89        86\n\n    accuracy                           0.85       121\n   macro avg       0.82      0.84      0.82       121\nweighted avg       0.86      0.85      0.85       121\n\n","output_type":"stream"}],"execution_count":128},{"cell_type":"markdown","source":"## **MULTI-CLASS(4HATE AND 1 NON-HATE) M-BERT**","metadata":{"id":"EoFgkupeERzU"}},{"cell_type":"code","source":"# No need for binary label anymore. Use 'SHORT LABLE' as is.\n# Clean the 'SHORT LABLE' column for binary classification\ndf['SHORT LABLE'] = df['SHORT LABLE'].str.strip()  # Remove extra spaces\n\n# Binary classification: 'H' (Hate) for labels ['C', 'G', 'P', 'R'], 'N' (Non-hate) otherwise\ndf['BINARY_LABEL'] = df['SHORT LABLE'].apply(lambda x: 'H' if x in ['C', 'G', 'P', 'R'] else 'N')\n","metadata":{"id":"C-X_cTqEERHK","execution":{"iopub.status.busy":"2024-10-30T08:19:15.711873Z","iopub.execute_input":"2024-10-30T08:19:15.712259Z","iopub.status.idle":"2024-10-30T08:19:15.719284Z","shell.execute_reply.started":"2024-10-30T08:19:15.712215Z","shell.execute_reply":"2024-10-30T08:19:15.718187Z"},"trusted":true},"outputs":[],"execution_count":129},{"cell_type":"code","source":"non_hate_count = df[df['SHORT LABLE'] == 'N'].shape[0]  # Count non-hate\nhate_count = df[df['SHORT LABLE'].isin(['C', 'G', 'P', 'R'])].shape[0]  # Count hate categories\n\n# Print the counts\nprint(f\"Number of Non-hate entries: {non_hate_count}\")\nprint(f\"Number of Hate entries (C, G, P, R): {hate_count}\")","metadata":{"id":"_sX6ste0Egr_","execution":{"iopub.status.busy":"2024-10-30T08:19:15.720605Z","iopub.execute_input":"2024-10-30T08:19:15.721254Z","iopub.status.idle":"2024-10-30T08:19:15.731781Z","shell.execute_reply.started":"2024-10-30T08:19:15.721209Z","shell.execute_reply":"2024-10-30T08:19:15.730964Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Number of Non-hate entries: 208\nNumber of Hate entries (C, G, P, R): 393\n","output_type":"stream"}],"execution_count":130},{"cell_type":"code","source":"# Count each hate category separately\nchar_assassination_count = df[df['SHORT LABLE'] == 'C'].shape[0]  # Character Assassination\ngender_count = df[df['SHORT LABLE'] == 'G'].shape[0]  # Gender/Sex based\npolitical_count = df[df['SHORT LABLE'] == 'P'].shape[0]  # Political\nreligion_count = df[df['SHORT LABLE'] == 'R'].shape[0]  # Religion\n\nprint(f\"Number of Character Assassination entries (C): {char_assassination_count}\")\nprint(f\"Number of Gender/Sex based entries (G): {gender_count}\")\nprint(f\"Number of Political entries (P): {political_count}\")\nprint(f\"Number of Religion entries (R): {religion_count}\")\n","metadata":{"id":"z5DOXx1_E2Qn","execution":{"iopub.status.busy":"2024-10-30T08:19:15.732807Z","iopub.execute_input":"2024-10-30T08:19:15.733124Z","iopub.status.idle":"2024-10-30T08:19:15.745279Z","shell.execute_reply.started":"2024-10-30T08:19:15.733077Z","shell.execute_reply":"2024-10-30T08:19:15.744374Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Number of Character Assassination entries (C): 132\nNumber of Gender/Sex based entries (G): 111\nNumber of Political entries (P): 68\nNumber of Religion entries (R): 82\n","output_type":"stream"}],"execution_count":131},{"cell_type":"code","source":"class HateSpeechDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n\n        # Tokenization\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': torch.tensor(label, dtype=torch.long)  # Label is now an integer for 5 classes\n        }\n","metadata":{"id":"xakKrj-tE3zd","execution":{"iopub.status.busy":"2024-10-30T08:19:15.746320Z","iopub.execute_input":"2024-10-30T08:19:15.746634Z","iopub.status.idle":"2024-10-30T08:19:15.759444Z","shell.execute_reply.started":"2024-10-30T08:19:15.746602Z","shell.execute_reply":"2024-10-30T08:19:15.758638Z"},"trusted":true},"outputs":[],"execution_count":132},{"cell_type":"code","source":"from transformers import BertForSequenceClassification\n\n# Define the model with 5 labels (Non-hate + 4 hate categories)\nmodel = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=5)\ntokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n","metadata":{"id":"xk8UdnclFEGw","execution":{"iopub.status.busy":"2024-10-30T08:19:15.760496Z","iopub.execute_input":"2024-10-30T08:19:15.760780Z","iopub.status.idle":"2024-10-30T08:19:16.386111Z","shell.execute_reply.started":"2024-10-30T08:19:15.760749Z","shell.execute_reply":"2024-10-30T08:19:16.385284Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":133},{"cell_type":"code","source":"# Set up optimizer and device\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n","metadata":{"id":"nc_uLpJFFGne","execution":{"iopub.status.busy":"2024-10-30T08:19:16.387174Z","iopub.execute_input":"2024-10-30T08:19:16.387484Z","iopub.status.idle":"2024-10-30T08:19:16.609731Z","shell.execute_reply.started":"2024-10-30T08:19:16.387453Z","shell.execute_reply":"2024-10-30T08:19:16.608770Z"},"trusted":true},"outputs":[],"execution_count":134},{"cell_type":"code","source":"# Split the dataset into training and testing sets\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(df['TRANSCRIPTION'], df['SHORT LABLE'], test_size=0.2)\n\n# Define label mapping for all 5 categories\nlabel_mapping = {\n    'N': 0,  # Non-hate\n    'C': 1,  # Character Assassination\n    'G': 2,  # Gender/Sex based\n    'P': 3,  # Political\n    'R': 4   # Religion\n}\n\n# Convert labels to integers for training\ntrain_labels = train_labels.map(label_mapping)\ntest_labels = test_labels.map(label_mapping)\n\n# Prepare train and test datasets using the HateSpeechDataset class\ntrain_dataset = HateSpeechDataset(train_texts.tolist(), train_labels.tolist(), tokenizer, max_len=128)\ntest_dataset = HateSpeechDataset(test_texts.tolist(), test_labels.tolist(), tokenizer, max_len=128)\n","metadata":{"id":"5rEvWRkSFSLm","execution":{"iopub.status.busy":"2024-10-30T08:19:16.610865Z","iopub.execute_input":"2024-10-30T08:19:16.611172Z","iopub.status.idle":"2024-10-30T08:19:16.620131Z","shell.execute_reply.started":"2024-10-30T08:19:16.611140Z","shell.execute_reply":"2024-10-30T08:19:16.619195Z"},"trusted":true},"outputs":[],"execution_count":135},{"cell_type":"code","source":"# Create DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=16)\n","metadata":{"id":"GkXgrlCKFUgv","execution":{"iopub.status.busy":"2024-10-30T08:19:16.621210Z","iopub.execute_input":"2024-10-30T08:19:16.621561Z","iopub.status.idle":"2024-10-30T08:19:16.669904Z","shell.execute_reply.started":"2024-10-30T08:19:16.621530Z","shell.execute_reply":"2024-10-30T08:19:16.668784Z"},"trusted":true},"outputs":[],"execution_count":136},{"cell_type":"code","source":"# Training loop\nfor epoch in range(25):  # Train for 3 epochs\n    model.train()\n    for batch in train_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n\n    print(f\"Epoch {epoch + 1} finished\")\n","metadata":{"id":"iH81jMZQFWEi","execution":{"iopub.status.busy":"2024-10-30T08:19:16.671559Z","iopub.execute_input":"2024-10-30T08:19:16.671879Z","iopub.status.idle":"2024-10-30T08:21:47.464045Z","shell.execute_reply.started":"2024-10-30T08:19:16.671845Z","shell.execute_reply":"2024-10-30T08:21:47.463066Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1 finished\nEpoch 2 finished\nEpoch 3 finished\nEpoch 4 finished\nEpoch 5 finished\nEpoch 6 finished\nEpoch 7 finished\nEpoch 8 finished\nEpoch 9 finished\nEpoch 10 finished\nEpoch 11 finished\nEpoch 12 finished\nEpoch 13 finished\nEpoch 14 finished\nEpoch 15 finished\nEpoch 16 finished\nEpoch 17 finished\nEpoch 18 finished\nEpoch 19 finished\nEpoch 20 finished\nEpoch 21 finished\nEpoch 22 finished\nEpoch 23 finished\nEpoch 24 finished\nEpoch 25 finished\n","output_type":"stream"}],"execution_count":137},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\n# Reverse label mapping: convert integers back to original labels\nlabel_mapping_reverse = {0: 'N', 1: 'C', 2: 'G', 3: 'P', 4: 'R'}\n\n# Testing loop: Generate test_preds and test_labels_eval\ntest_preds = []\ntest_labels_eval = []\n\nmodel.eval()\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n        test_preds.extend(preds)\n        test_labels_eval.extend(labels.cpu().numpy())\n\n# Convert integer labels back to original string labels for test data\ntest_preds = [label_mapping_reverse[pred] for pred in test_preds]\ntest_labels_eval = [label_mapping_reverse[label] for label in test_labels_eval]\n\n# Check unique classes in the true labels and predictions\nprint(f\"Unique classes in test_labels_eval: {set(test_labels_eval)}\")\nprint(f\"Unique classes in test_preds: {set(test_preds)}\")\n\n# Define the expected labels (all 5 classes)\nexpected_labels = ['N', 'C', 'G', 'P', 'R']\n\n# Evaluate accuracy on testing data\ntest_accuracy = accuracy_score(test_labels_eval, test_preds)\nprint(f'Test Data Accuracy: {test_accuracy}')\n\n# Generate classification report and handle missing classes\nprint(classification_report(test_labels_eval, test_preds, labels=expected_labels, target_names=expected_labels))","metadata":{"id":"VZjdhvf1FXfq","execution":{"iopub.status.busy":"2024-10-30T08:21:47.465364Z","iopub.execute_input":"2024-10-30T08:21:47.465703Z","iopub.status.idle":"2024-10-30T08:21:48.194224Z","shell.execute_reply.started":"2024-10-30T08:21:47.465667Z","shell.execute_reply":"2024-10-30T08:21:48.193237Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Unique classes in test_labels_eval: {'G', 'N', 'C', 'P', 'R'}\nUnique classes in test_preds: {'G', 'N', 'C', 'P', 'R'}\nTest Data Accuracy: 0.7603305785123967\n              precision    recall  f1-score   support\n\n           N       0.74      0.84      0.79        38\n           C       0.81      0.76      0.79        29\n           G       0.67      0.64      0.65        22\n           P       0.86      0.67      0.75        18\n           R       0.75      0.86      0.80        14\n\n    accuracy                           0.76       121\n   macro avg       0.77      0.75      0.76       121\nweighted avg       0.76      0.76      0.76       121\n\n","output_type":"stream"}],"execution_count":138},{"cell_type":"markdown","source":"### **FOR BINARY CLASSIFICATION(XLM-Roberta)**","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport torch\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:21:48.195998Z","iopub.execute_input":"2024-10-30T08:21:48.196350Z","iopub.status.idle":"2024-10-30T08:21:48.201650Z","shell.execute_reply.started":"2024-10-30T08:21:48.196295Z","shell.execute_reply":"2024-10-30T08:21:48.200621Z"},"trusted":true},"outputs":[],"execution_count":139},{"cell_type":"code","source":"# Load your dataset from an Excel file\ndf = pd.read_excel('/kaggle/input/dataset1/TELUGU_METADATA.xlsx')\n\n# Binary classification based on 'AUDIO FILE NAME'\ndf['BINARY_LABEL'] = df['AUDIO FILE NAME'].apply(lambda x: 'H' if x.startswith('H') else 'NH')\n\n# Print counts for each class\nprint(\"Binary Label Counts:\")\nprint(df['BINARY_LABEL'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:21:48.202887Z","iopub.execute_input":"2024-10-30T08:21:48.203171Z","iopub.status.idle":"2024-10-30T08:21:48.370023Z","shell.execute_reply.started":"2024-10-30T08:21:48.203140Z","shell.execute_reply":"2024-10-30T08:21:48.369109Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Binary Label Counts:\nBINARY_LABEL\nH     392\nNH    209\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":140},{"cell_type":"code","source":"from transformers import XLMRobertaTokenizer, BertForSequenceClassification\n\n# Define the model with 5 labels (Non-hate + 4 hate categories)\nmodel = BertForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=5)\ntokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:21:48.371246Z","iopub.execute_input":"2024-10-30T08:21:48.371913Z","iopub.status.idle":"2024-10-30T08:21:53.948554Z","shell.execute_reply.started":"2024-10-30T08:21:48.371868Z","shell.execute_reply":"2024-10-30T08:21:53.947719Z"},"trusted":true},"outputs":[{"name":"stderr","text":"You are using a model of type xlm-roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":141},{"cell_type":"code","source":"class HateSpeechDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len, binary=False):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.binary = binary  # Flag to indicate binary or multi-class\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n\n        # Tokenization\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        # Label: For binary, 'NH' as 0, 'H' as 1. Multi-class uses label mapping\n        label_value = torch.tensor(1 if label == 'H' else 0, dtype=torch.long) if self.binary else torch.tensor(label, dtype=torch.long)\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': label_value\n        }\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:21:53.949738Z","iopub.execute_input":"2024-10-30T08:21:53.950060Z","iopub.status.idle":"2024-10-30T08:21:53.959269Z","shell.execute_reply.started":"2024-10-30T08:21:53.950027Z","shell.execute_reply":"2024-10-30T08:21:53.958399Z"},"trusted":true},"outputs":[],"execution_count":142},{"cell_type":"code","source":"# Set up device for GPU if available, else use CPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:21:53.960607Z","iopub.execute_input":"2024-10-30T08:21:53.960993Z","iopub.status.idle":"2024-10-30T08:21:53.973774Z","shell.execute_reply.started":"2024-10-30T08:21:53.960952Z","shell.execute_reply":"2024-10-30T08:21:53.973099Z"},"trusted":true},"outputs":[],"execution_count":143},{"cell_type":"code","source":"from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\n\n# Define the tokenizer and model for binary classification (Hate vs. Non-Hate)\ntokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\nbinary_model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=2)\nbinary_model = binary_model.to(device)\n\n# Set up the optimizer\nbinary_optimizer = torch.optim.AdamW(binary_model.parameters(), lr=1e-5)\n\n# Split dataset for binary classification\nbinary_train_texts, binary_test_texts, binary_train_labels, binary_test_labels = train_test_split(\n    df['TRANSCRIPTION'], df['BINARY_LABEL'], test_size=0.2\n)\n\n# Binary Dataset and DataLoader\nbinary_train_dataset = HateSpeechDataset(binary_train_texts.tolist(), binary_train_labels.tolist(), tokenizer, max_len=128, binary=True)\nbinary_test_dataset = HateSpeechDataset(binary_test_texts.tolist(), binary_test_labels.tolist(), tokenizer, max_len=128, binary=True)\n\nbinary_train_loader = DataLoader(binary_train_dataset, batch_size=16, shuffle=True)\nbinary_test_loader = DataLoader(binary_test_dataset, batch_size=16)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:21:53.975099Z","iopub.execute_input":"2024-10-30T08:21:53.975596Z","iopub.status.idle":"2024-10-30T08:21:57.337227Z","shell.execute_reply.started":"2024-10-30T08:21:53.975553Z","shell.execute_reply":"2024-10-30T08:21:57.336444Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":144},{"cell_type":"code","source":"# Binary Classification Training Loop\nfor epoch in range(25):  # You can adjust the number of epochs\n    binary_model.train()\n    for batch in binary_train_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        binary_optimizer.zero_grad()\n        outputs = binary_model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        binary_optimizer.step()\n\n    print(f\"Epoch {epoch + 1}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:21:57.338377Z","iopub.execute_input":"2024-10-30T08:21:57.338691Z","iopub.status.idle":"2024-10-30T08:24:40.788342Z","shell.execute_reply.started":"2024-10-30T08:21:57.338658Z","shell.execute_reply":"2024-10-30T08:24:40.787377Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1\nEpoch 2\nEpoch 3\nEpoch 4\nEpoch 5\nEpoch 6\nEpoch 7\nEpoch 8\nEpoch 9\nEpoch 10\nEpoch 11\nEpoch 12\nEpoch 13\nEpoch 14\nEpoch 15\nEpoch 16\nEpoch 17\nEpoch 18\nEpoch 19\nEpoch 20\nEpoch 21\nEpoch 22\nEpoch 23\nEpoch 24\nEpoch 25\n","output_type":"stream"}],"execution_count":145},{"cell_type":"code","source":"# Testing Binary Classification Model\nbinary_test_preds = []\nbinary_test_labels_eval = []\n\nbinary_model.eval()\nwith torch.no_grad():\n    for batch in binary_test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        outputs = binary_model(input_ids, attention_mask=attention_mask)\n        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n        binary_test_preds.extend(preds)\n        binary_test_labels_eval.extend(labels.cpu().numpy())\n\n# Evaluate binary accuracy\nbinary_accuracy = accuracy_score(binary_test_labels_eval, binary_test_preds)\nprint(f\"Binary Classification Accuracy: {binary_accuracy}\")\nprint(classification_report(binary_test_labels_eval, binary_test_preds, target_names=['Non-Hate', 'Hate']))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:24:40.789648Z","iopub.execute_input":"2024-10-30T08:24:40.790045Z","iopub.status.idle":"2024-10-30T08:24:41.441599Z","shell.execute_reply.started":"2024-10-30T08:24:40.790000Z","shell.execute_reply":"2024-10-30T08:24:41.440658Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Binary Classification Accuracy: 0.9008264462809917\n              precision    recall  f1-score   support\n\n    Non-Hate       0.84      0.88      0.86        41\n        Hate       0.94      0.91      0.92        80\n\n    accuracy                           0.90       121\n   macro avg       0.89      0.90      0.89       121\nweighted avg       0.90      0.90      0.90       121\n\n","output_type":"stream"}],"execution_count":146},{"cell_type":"markdown","source":"## **MULTI-CLASS(4HATE AND 1 NON-HATE) XLM-RoBERT**","metadata":{}},{"cell_type":"code","source":"# No need for binary label anymore. Use 'SHORT LABLE' as is.\n# Clean the 'SHORT LABLE' column for binary classification\ndf['SHORT LABLE'] = df['SHORT LABLE'].str.strip()  # Remove extra spaces\n\n# Binary classification: 'H' (Hate) for labels ['C', 'G', 'P', 'R'], 'N' (Non-hate) otherwise\ndf['BINARY_LABEL'] = df['SHORT LABLE'].apply(lambda x: 'H' if x in ['C', 'G', 'P', 'R'] else 'N')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:24:41.442918Z","iopub.execute_input":"2024-10-30T08:24:41.443646Z","iopub.status.idle":"2024-10-30T08:24:41.450733Z","shell.execute_reply.started":"2024-10-30T08:24:41.443599Z","shell.execute_reply":"2024-10-30T08:24:41.449832Z"},"trusted":true},"outputs":[],"execution_count":147},{"cell_type":"code","source":"non_hate_count = df[df['SHORT LABLE'] == 'N'].shape[0]  # Count non-hate\nhate_count = df[df['SHORT LABLE'].isin(['C', 'G', 'P', 'R'])].shape[0]  # Count hate categories\n\n# Print the counts\nprint(f\"Number of Non-hate entries: {non_hate_count}\")\nprint(f\"Number of Hate entries (C, G, P, R): {hate_count}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:24:41.451795Z","iopub.execute_input":"2024-10-30T08:24:41.452047Z","iopub.status.idle":"2024-10-30T08:24:41.465661Z","shell.execute_reply.started":"2024-10-30T08:24:41.452019Z","shell.execute_reply":"2024-10-30T08:24:41.464597Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Number of Non-hate entries: 208\nNumber of Hate entries (C, G, P, R): 393\n","output_type":"stream"}],"execution_count":148},{"cell_type":"code","source":"# Count each hate category separately\nchar_assassination_count = df[df['SHORT LABLE'] == 'C'].shape[0]  # Character Assassination\ngender_count = df[df['SHORT LABLE'] == 'G'].shape[0]  # Gender/Sex based\npolitical_count = df[df['SHORT LABLE'] == 'P'].shape[0]  # Political\nreligion_count = df[df['SHORT LABLE'] == 'R'].shape[0]  # Religion\n\nprint(f\"Number of Character Assassination entries (C): {char_assassination_count}\")\nprint(f\"Number of Gender/Sex based entries (G): {gender_count}\")\nprint(f\"Number of Political entries (P): {political_count}\")\nprint(f\"Number of Religion entries (R): {religion_count}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:24:41.466679Z","iopub.execute_input":"2024-10-30T08:24:41.466968Z","iopub.status.idle":"2024-10-30T08:24:41.480508Z","shell.execute_reply.started":"2024-10-30T08:24:41.466938Z","shell.execute_reply":"2024-10-30T08:24:41.479593Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Number of Character Assassination entries (C): 132\nNumber of Gender/Sex based entries (G): 111\nNumber of Political entries (P): 68\nNumber of Religion entries (R): 82\n","output_type":"stream"}],"execution_count":149},{"cell_type":"code","source":"class HateSpeechDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n\n        # Tokenization\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': torch.tensor(label, dtype=torch.long)  # Label is now an integer for 5 classes\n        }\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:24:41.481586Z","iopub.execute_input":"2024-10-30T08:24:41.481869Z","iopub.status.idle":"2024-10-30T08:24:41.497158Z","shell.execute_reply.started":"2024-10-30T08:24:41.481839Z","shell.execute_reply":"2024-10-30T08:24:41.496462Z"},"trusted":true},"outputs":[],"execution_count":150},{"cell_type":"code","source":"from transformers import BertForSequenceClassification\n\n# Define the model with 5 labels (Non-hate + 4 hate categories)\nmodel = BertForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=5)\ntokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:24:41.498189Z","iopub.execute_input":"2024-10-30T08:24:41.498563Z","iopub.status.idle":"2024-10-30T08:24:46.977690Z","shell.execute_reply.started":"2024-10-30T08:24:41.498521Z","shell.execute_reply":"2024-10-30T08:24:46.976862Z"},"trusted":true},"outputs":[{"name":"stderr","text":"You are using a model of type xlm-roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":151},{"cell_type":"code","source":"# Set up optimizer and device\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:24:46.978775Z","iopub.execute_input":"2024-10-30T08:24:46.979082Z","iopub.status.idle":"2024-10-30T08:24:47.283884Z","shell.execute_reply.started":"2024-10-30T08:24:46.979049Z","shell.execute_reply":"2024-10-30T08:24:47.283057Z"},"trusted":true},"outputs":[],"execution_count":152},{"cell_type":"code","source":"# Split the dataset into training and testing sets\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(df['TRANSCRIPTION'], df['SHORT LABLE'], test_size=0.2)\n\n# Define label mapping for all 5 categories\nlabel_mapping = {\n    'N': 0,  # Non-hate\n    'C': 1,  # Character Assassination\n    'G': 2,  # Gender/Sex based\n    'P': 3,  # Political\n    'R': 4   # Religion\n}\n\n# Convert labels to integers for training\ntrain_labels = train_labels.map(label_mapping)\ntest_labels = test_labels.map(label_mapping)\n\n# Prepare train and test datasets using the HateSpeechDataset class\ntrain_dataset = HateSpeechDataset(train_texts.tolist(), train_labels.tolist(), tokenizer, max_len=128)\ntest_dataset = HateSpeechDataset(test_texts.tolist(), test_labels.tolist(), tokenizer, max_len=128)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:24:47.285066Z","iopub.execute_input":"2024-10-30T08:24:47.285398Z","iopub.status.idle":"2024-10-30T08:24:47.294466Z","shell.execute_reply.started":"2024-10-30T08:24:47.285358Z","shell.execute_reply":"2024-10-30T08:24:47.293510Z"},"trusted":true},"outputs":[],"execution_count":153},{"cell_type":"code","source":"# Create DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:24:47.295694Z","iopub.execute_input":"2024-10-30T08:24:47.296435Z","iopub.status.idle":"2024-10-30T08:24:47.311999Z","shell.execute_reply.started":"2024-10-30T08:24:47.296391Z","shell.execute_reply":"2024-10-30T08:24:47.311069Z"},"trusted":true},"outputs":[],"execution_count":154},{"cell_type":"code","source":"# Training loop\nfor epoch in range(25):  \n    model.train()\n    for batch in train_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n\n    print(f\"Epoch {epoch + 1} finished\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:24:47.314250Z","iopub.execute_input":"2024-10-30T08:24:47.314582Z","iopub.status.idle":"2024-10-30T08:27:08.628229Z","shell.execute_reply.started":"2024-10-30T08:24:47.314551Z","shell.execute_reply":"2024-10-30T08:27:08.627242Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1 finished\nEpoch 2 finished\nEpoch 3 finished\nEpoch 4 finished\nEpoch 5 finished\nEpoch 6 finished\nEpoch 7 finished\nEpoch 8 finished\nEpoch 9 finished\nEpoch 10 finished\nEpoch 11 finished\nEpoch 12 finished\nEpoch 13 finished\nEpoch 14 finished\nEpoch 15 finished\nEpoch 16 finished\nEpoch 17 finished\nEpoch 18 finished\nEpoch 19 finished\nEpoch 20 finished\nEpoch 21 finished\nEpoch 22 finished\nEpoch 23 finished\nEpoch 24 finished\nEpoch 25 finished\n","output_type":"stream"}],"execution_count":155},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\n# Reverse label mapping: convert integers back to original labels\nlabel_mapping_reverse = {0: 'N', 1: 'C', 2: 'G', 3: 'P', 4: 'R'}\n\n# Testing loop: Generate test_preds and test_labels_eval\ntest_preds = []\ntest_labels_eval = []\n\nmodel.eval()\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n        test_preds.extend(preds)\n        test_labels_eval.extend(labels.cpu().numpy())\n\n# Convert integer labels back to original string labels for test data\ntest_preds = [label_mapping_reverse[pred] for pred in test_preds]\ntest_labels_eval = [label_mapping_reverse[label] for label in test_labels_eval]\n\n# Check unique classes in the true labels and predictions\nprint(f\"Unique classes in test_labels_eval: {set(test_labels_eval)}\")\nprint(f\"Unique classes in test_preds: {set(test_preds)}\")\n\n# Define the expected labels (all 5 classes)\nexpected_labels = ['N', 'C', 'G', 'P', 'R']\n\n# Evaluate accuracy on testing data\ntest_accuracy = accuracy_score(test_labels_eval, test_preds)\nprint(f'Test Data Accuracy: {test_accuracy}')\n\n# Generate classification report and handle missing classes\nprint(classification_report(test_labels_eval, test_preds, labels=expected_labels, target_names=expected_labels))","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:27:08.629273Z","iopub.execute_input":"2024-10-30T08:27:08.629582Z","iopub.status.idle":"2024-10-30T08:27:09.429896Z","shell.execute_reply.started":"2024-10-30T08:27:08.629550Z","shell.execute_reply":"2024-10-30T08:27:09.428937Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Unique classes in test_labels_eval: {'G', 'N', 'C', 'P', 'R'}\nUnique classes in test_preds: {'G', 'N', 'C', 'P', 'R'}\nTest Data Accuracy: 0.6446280991735537\n              precision    recall  f1-score   support\n\n           N       0.64      0.85      0.73        46\n           C       0.71      0.81      0.76        21\n           G       0.62      0.53      0.57        19\n           P       0.53      0.57      0.55        14\n           R       0.80      0.19      0.31        21\n\n    accuracy                           0.64       121\n   macro avg       0.66      0.59      0.58       121\nweighted avg       0.66      0.64      0.62       121\n\n","output_type":"stream"}],"execution_count":156},{"cell_type":"markdown","source":"### ****BINARY CLASSIFICATION(XGBOOST with BERT)****","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport torch\nimport numpy as np\nfrom transformers import BertTokenizer, BertModel\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:27:09.431169Z","iopub.execute_input":"2024-10-30T08:27:09.432985Z","iopub.status.idle":"2024-10-30T08:27:09.437397Z","shell.execute_reply.started":"2024-10-30T08:27:09.432947Z","shell.execute_reply":"2024-10-30T08:27:09.436526Z"},"trusted":true},"outputs":[],"execution_count":157},{"cell_type":"code","source":"# Load your dataset from an Excel file\ndf = pd.read_excel('/kaggle/input/dataset1/TELUGU_METADATA.xlsx')  # Adjust path as necessary\n\n# Create binary labels from AUDIO FILE NAME (Hate vs. Non-hate)\ndf['BINARY_LABEL'] = df['AUDIO FILE NAME'].apply(lambda x: 1 if x.startswith('H_') else 0)\n\n# Split dataset for binary classification\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(\n    df['TRANSCRIPTION'], df['BINARY_LABEL'], test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:27:09.438570Z","iopub.execute_input":"2024-10-30T08:27:09.438881Z","iopub.status.idle":"2024-10-30T08:27:09.605881Z","shell.execute_reply.started":"2024-10-30T08:27:09.438849Z","shell.execute_reply":"2024-10-30T08:27:09.605106Z"},"trusted":true},"outputs":[],"execution_count":158},{"cell_type":"code","source":"# Load pre-trained BERT model and tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\nbert_model = BertModel.from_pretrained('bert-base-multilingual-cased')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:27:09.607034Z","iopub.execute_input":"2024-10-30T08:27:09.607362Z","iopub.status.idle":"2024-10-30T08:27:10.227174Z","shell.execute_reply.started":"2024-10-30T08:27:09.607314Z","shell.execute_reply":"2024-10-30T08:27:10.226162Z"},"trusted":true},"outputs":[],"execution_count":159},{"cell_type":"code","source":"# Function to extract BERT embeddings for each sentence\ndef extract_bert_embeddings(texts, tokenizer, model, max_len=128):\n    model.eval()\n    embeddings = []\n    with torch.no_grad():\n        for text in texts:\n            # Tokenize and encode the text for BERT\n            inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=max_len)\n            outputs = model(**inputs)\n            # CLS token representation as the sentence embedding\n            embeddings.append(outputs.last_hidden_state[:, 0, :].cpu().numpy())\n    return np.concatenate(embeddings, axis=0)\n\n# Extract BERT embeddings for train and test sets\ntrain_embeddings = extract_bert_embeddings(train_texts.tolist(), tokenizer, bert_model)\ntest_embeddings = extract_bert_embeddings(test_texts.tolist(), tokenizer, bert_model)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:27:10.228798Z","iopub.execute_input":"2024-10-30T08:27:10.229103Z","iopub.status.idle":"2024-10-30T08:28:29.254507Z","shell.execute_reply.started":"2024-10-30T08:27:10.229071Z","shell.execute_reply":"2024-10-30T08:28:29.253385Z"},"trusted":true},"outputs":[],"execution_count":160},{"cell_type":"code","source":"# Initialize XGBoost classifier for binary classification\nxgb_model = XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss')\n\n# Train XGBoost on the BERT embeddings\nxgb_model.fit(train_embeddings, train_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:28:29.255937Z","iopub.execute_input":"2024-10-30T08:28:29.256894Z","iopub.status.idle":"2024-10-30T08:28:31.268159Z","shell.execute_reply.started":"2024-10-30T08:28:29.256856Z","shell.execute_reply":"2024-10-30T08:28:31.267193Z"},"trusted":true},"outputs":[{"execution_count":161,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='logloss',\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n              n_jobs=None, num_parallel_tree=None, random_state=None, ...)","text/html":"<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":161},{"cell_type":"code","source":"# Predict on the test embeddings\ntest_preds = xgb_model.predict(test_embeddings)\n\n# Evaluate the model performance\naccuracy = accuracy_score(test_labels, test_preds)\nreport = classification_report(test_labels, test_preds, target_names=[\"Non-Hate\", \"Hate\"])\n\n# Print accuracy and classification report\nprint(f\"Test Accuracy: {accuracy}\")\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:28:31.269369Z","iopub.execute_input":"2024-10-30T08:28:31.269697Z","iopub.status.idle":"2024-10-30T08:28:31.285911Z","shell.execute_reply.started":"2024-10-30T08:28:31.269664Z","shell.execute_reply":"2024-10-30T08:28:31.285002Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.7933884297520661\n              precision    recall  f1-score   support\n\n    Non-Hate       0.74      0.62      0.68        42\n        Hate       0.81      0.89      0.85        79\n\n    accuracy                           0.79       121\n   macro avg       0.78      0.75      0.76       121\nweighted avg       0.79      0.79      0.79       121\n\n","output_type":"stream"}],"execution_count":162},{"cell_type":"markdown","source":"## **MULTI-CLASS(4HATE AND 1 NON-HATE) XLM-RoBERT**","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport torch\nimport numpy as np\nfrom transformers import BertTokenizer, BertModel\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:28:31.287269Z","iopub.execute_input":"2024-10-30T08:28:31.287592Z","iopub.status.idle":"2024-10-30T08:28:31.292569Z","shell.execute_reply.started":"2024-10-30T08:28:31.287560Z","shell.execute_reply":"2024-10-30T08:28:31.291532Z"},"trusted":true},"outputs":[],"execution_count":163},{"cell_type":"code","source":"# Define multiclass labels based on 'SHORT LABLE' column\nlabel_mapping = {'N': 0, 'C': 1, 'G': 2, 'P': 3, 'R': 4}  # Modify as needed for your classes\ndf['MULTI_LABEL'] = df['SHORT LABLE'].map(label_mapping)\n\n# Split dataset for multiclass classification\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(\n    df['TRANSCRIPTION'], df['MULTI_LABEL'], test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:28:31.293740Z","iopub.execute_input":"2024-10-30T08:28:31.294039Z","iopub.status.idle":"2024-10-30T08:28:31.307791Z","shell.execute_reply.started":"2024-10-30T08:28:31.294006Z","shell.execute_reply":"2024-10-30T08:28:31.306861Z"},"trusted":true},"outputs":[],"execution_count":164},{"cell_type":"code","source":"# Load pre-trained BERT model and tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\nbert_model = BertModel.from_pretrained('bert-base-multilingual-cased')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:28:31.309042Z","iopub.execute_input":"2024-10-30T08:28:31.309839Z","iopub.status.idle":"2024-10-30T08:28:31.970806Z","shell.execute_reply.started":"2024-10-30T08:28:31.309794Z","shell.execute_reply":"2024-10-30T08:28:31.969722Z"},"trusted":true},"outputs":[],"execution_count":165},{"cell_type":"code","source":"# Function to extract BERT embeddings for each sentence\ndef extract_bert_embeddings(texts, tokenizer, model, max_len=128):\n    model.eval()\n    embeddings = []\n    with torch.no_grad():\n        for text in texts:\n            # Tokenize and encode the text for BERT\n            inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=max_len)\n            outputs = model(**inputs)\n            # CLS token representation as the sentence embedding\n            embeddings.append(outputs.last_hidden_state[:, 0, :].cpu().numpy())\n    return np.concatenate(embeddings, axis=0)\n\n# Extract BERT embeddings for train and test sets\ntrain_embeddings = extract_bert_embeddings(train_texts.tolist(), tokenizer, bert_model)\ntest_embeddings = extract_bert_embeddings(test_texts.tolist(), tokenizer, bert_model)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:28:31.972110Z","iopub.execute_input":"2024-10-30T08:28:31.972448Z","iopub.status.idle":"2024-10-30T08:29:53.458028Z","shell.execute_reply.started":"2024-10-30T08:28:31.972414Z","shell.execute_reply":"2024-10-30T08:29:53.456986Z"},"trusted":true},"outputs":[],"execution_count":166},{"cell_type":"code","source":"# Initialize XGBoost classifier for multiclass classification\nxgb_model = XGBClassifier(n_estimators=500, use_label_encoder=False, eval_metric='mlogloss', objective='multi:softmax', num_class=len(label_mapping))\n\n# Train XGBoost on the BERT embeddings\nxgb_model.fit(train_embeddings, train_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:29:53.461674Z","iopub.execute_input":"2024-10-30T08:29:53.461990Z","iopub.status.idle":"2024-10-30T08:30:07.440966Z","shell.execute_reply.started":"2024-10-30T08:29:53.461958Z","shell.execute_reply":"2024-10-30T08:30:07.439986Z"},"trusted":true},"outputs":[{"execution_count":167,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='mlogloss',\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n              n_jobs=None, num_class=5, num_parallel_tree=None, ...)","text/html":"<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n              n_jobs=None, num_class=5, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n              n_jobs=None, num_class=5, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":167},{"cell_type":"code","source":"# Predict on the test embeddings\ntest_preds = xgb_model.predict(test_embeddings)\n\n# Evaluate the model performance\naccuracy = accuracy_score(test_labels, test_preds)\nreport = classification_report(test_labels, test_preds, target_names=list(label_mapping.keys()))\n\n# Print accuracy and classification report\nprint(f\"Test Accuracy: {accuracy}\")\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:30:07.442640Z","iopub.execute_input":"2024-10-30T08:30:07.443030Z","iopub.status.idle":"2024-10-30T08:30:07.460941Z","shell.execute_reply.started":"2024-10-30T08:30:07.442989Z","shell.execute_reply":"2024-10-30T08:30:07.459948Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.5537190082644629\n              precision    recall  f1-score   support\n\n           N       0.55      0.74      0.63        42\n           C       0.54      0.64      0.58        22\n           G       0.44      0.35      0.39        23\n           P       0.75      0.40      0.52        15\n           R       0.62      0.42      0.50        19\n\n    accuracy                           0.55       121\n   macro avg       0.58      0.51      0.53       121\nweighted avg       0.56      0.55      0.54       121\n\n","output_type":"stream"}],"execution_count":168},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load dataset and set up binary labels\ndf = pd.read_excel('/kaggle/input/dataset1/TELUGU_METADATA.xlsx')\ndf['BINARY_LABEL'] = df['AUDIO FILE NAME'].apply(lambda x: 'H' if x.startswith('H') else 'NH')\n\n# TF-IDF Vectorization\ntfidf = TfidfVectorizer(max_features=5000)\nX = tfidf.fit_transform(df['TRANSCRIPTION']).toarray()\ny = df['BINARY_LABEL'].map({'NH': 0, 'H': 1})\n\n# Split into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# SVM Model Training\nsvm_model = SVC(kernel='linear')\nsvm_model.fit(X_train, y_train)\n\n# Prediction and evaluation\ny_pred = svm_model.predict(X_test)\nprint(f\"SVM Binary Classification Accuracy: {accuracy_score(y_test, y_pred)}\")\nprint(classification_report(y_test, y_pred, target_names=['Non-Hate', 'Hate']))\n\n# Transformer-based binary classification using XLM-Roberta\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:52:24.548475Z","iopub.execute_input":"2024-10-30T08:52:24.549217Z","iopub.status.idle":"2024-10-30T08:52:24.822822Z","shell.execute_reply.started":"2024-10-30T08:52:24.549176Z","shell.execute_reply":"2024-10-30T08:52:24.821886Z"},"trusted":true},"outputs":[{"name":"stdout","text":"SVM Binary Classification Accuracy: 0.768595041322314\n              precision    recall  f1-score   support\n\n    Non-Hate       0.67      0.60      0.63        40\n        Hate       0.81      0.85      0.83        81\n\n    accuracy                           0.77       121\n   macro avg       0.74      0.73      0.73       121\nweighted avg       0.76      0.77      0.77       121\n\n","output_type":"stream"}],"execution_count":193},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pandas as pd\n\n# Assuming df is your DataFrame with columns \"TRANSCRIPTION\" and \"SHORT LABLE\"\n# Define label mapping for all 5 categories\nlabel_mapping = {'N': 0, 'C': 1, 'G': 2, 'P': 3, 'R': 4}\ndf['SHORT LABLE'] = df['SHORT LABLE'].map(label_mapping)\n\n# Split the dataset into training and testing sets\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(\n    df['TRANSCRIPTION'], df['SHORT LABLE'], test_size=0.2, random_state=42)\n\n# TF-IDF Vectorization\ntfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\nX_train_tfidf = tfidf_vectorizer.fit_transform(train_texts)\nX_test_tfidf = tfidf_vectorizer.transform(test_texts)\n\n# SVM Classifier\nsvm_model = SVC(kernel='linear', C=1)\nsvm_model.fit(X_train_tfidf, train_labels)\n\n# Predict and Evaluate\ntfidf_svm_preds = svm_model.predict(X_test_tfidf)\ntfidf_svm_accuracy = accuracy_score(test_labels, tfidf_svm_preds)\nprint(f\"TF-IDF + SVM Accuracy: {tfidf_svm_accuracy}\")\nprint(classification_report(test_labels, tfidf_svm_preds, target_names=label_mapping.keys()))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:43:41.206029Z","iopub.execute_input":"2024-10-30T08:43:41.206437Z","iopub.status.idle":"2024-10-30T08:43:41.340213Z","shell.execute_reply.started":"2024-10-30T08:43:41.206399Z","shell.execute_reply":"2024-10-30T08:43:41.339346Z"},"trusted":true},"outputs":[{"name":"stdout","text":"TF-IDF + SVM Accuracy: 0.5454545454545454\n              precision    recall  f1-score   support\n\n           N       0.50      0.88      0.64        42\n           C       0.55      0.55      0.55        22\n           G       0.64      0.39      0.49        23\n           P       0.67      0.13      0.22        15\n           R       0.75      0.32      0.44        19\n\n    accuracy                           0.55       121\n   macro avg       0.62      0.45      0.47       121\nweighted avg       0.60      0.55      0.51       121\n\n","output_type":"stream"}],"execution_count":187},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load dataset and set up binary labels\ndf = pd.read_excel('/kaggle/input/dataset1/TELUGU_METADATA.xlsx')\ndf['BINARY_LABEL'] = df['AUDIO FILE NAME'].apply(lambda x: 'H' if x.startswith('H') else 'NH')\n\n# TF-IDF Vectorization\ntfidf = TfidfVectorizer(max_features=5000)\nX = tfidf.fit_transform(df['TRANSCRIPTION']).toarray()\ny = df['BINARY_LABEL'].map({'NH': 0, 'H': 1})\n\n# Split into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Logistic Regression Model Training\nlog_reg_model = LogisticRegression(max_iter=1000)\nlog_reg_model.fit(X_train, y_train)\n\n# Prediction and evaluation\ny_pred = log_reg_model.predict(X_test)\nprint(f\"Logistic Regression Binary Classification Accuracy: {accuracy_score(y_test, y_pred)}\")\nprint(classification_report(y_test, y_pred, target_names=['Non-Hate', 'Hate']))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:56:33.398999Z","iopub.execute_input":"2024-10-30T08:56:33.399419Z","iopub.status.idle":"2024-10-30T08:56:33.676095Z","shell.execute_reply.started":"2024-10-30T08:56:33.399380Z","shell.execute_reply":"2024-10-30T08:56:33.674618Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Logistic Regression Binary Classification Accuracy: 0.7520661157024794\n              precision    recall  f1-score   support\n\n    Non-Hate       0.88      0.33      0.48        42\n        Hate       0.73      0.97      0.84        79\n\n    accuracy                           0.75       121\n   macro avg       0.80      0.65      0.66       121\nweighted avg       0.78      0.75      0.71       121\n\n","output_type":"stream"}],"execution_count":194},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Random Forest Model Training\nrf_model = RandomForestClassifier(n_estimators=100)\nrf_model.fit(X_train, y_train)\n\n# Prediction and evaluation\ny_pred = rf_model.predict(X_test)\nprint(f\"Random Forest Binary Classification Accuracy: {accuracy_score(y_test, y_pred)}\")\nprint(classification_report(y_test, y_pred, target_names=['Non-Hate', 'Hate']))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:56:40.997831Z","iopub.execute_input":"2024-10-30T08:56:40.998194Z","iopub.status.idle":"2024-10-30T08:56:41.341875Z","shell.execute_reply.started":"2024-10-30T08:56:40.998161Z","shell.execute_reply":"2024-10-30T08:56:41.340806Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Random Forest Binary Classification Accuracy: 0.8099173553719008\n              precision    recall  f1-score   support\n\n    Non-Hate       0.95      0.48      0.63        42\n        Hate       0.78      0.99      0.87        79\n\n    accuracy                           0.81       121\n   macro avg       0.87      0.73      0.75       121\nweighted avg       0.84      0.81      0.79       121\n\n","output_type":"stream"}],"execution_count":195},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n# K-Nearest Neighbors Model Training\nknn_model = KNeighborsClassifier(n_neighbors=5)\nknn_model.fit(X_train, y_train)\n\n# Prediction and evaluation\ny_pred = knn_model.predict(X_test)\nprint(f\"K-Nearest Neighbors Binary Classification Accuracy: {accuracy_score(y_test, y_pred)}\")\nprint(classification_report(y_test, y_pred, target_names=['Non-Hate', 'Hate']))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:56:46.801237Z","iopub.execute_input":"2024-10-30T08:56:46.801660Z","iopub.status.idle":"2024-10-30T08:56:47.020248Z","shell.execute_reply.started":"2024-10-30T08:56:46.801623Z","shell.execute_reply":"2024-10-30T08:56:47.019180Z"},"trusted":true},"outputs":[{"name":"stdout","text":"K-Nearest Neighbors Binary Classification Accuracy: 0.7272727272727273\n              precision    recall  f1-score   support\n\n    Non-Hate       0.91      0.24      0.38        42\n        Hate       0.71      0.99      0.83        79\n\n    accuracy                           0.73       121\n   macro avg       0.81      0.61      0.60       121\nweighted avg       0.78      0.73      0.67       121\n\n","output_type":"stream"}],"execution_count":196},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n# Decision Tree Model Training\ndt_model = DecisionTreeClassifier()\ndt_model.fit(X_train, y_train)\n\n# Prediction and evaluation\ny_pred = dt_model.predict(X_test)\nprint(f\"Decision Tree Binary Classification Accuracy: {accuracy_score(y_test, y_pred)}\")\nprint(classification_report(y_test, y_pred, target_names=['Non-Hate', 'Hate']))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:56:58.018024Z","iopub.execute_input":"2024-10-30T08:56:58.018726Z","iopub.status.idle":"2024-10-30T08:56:58.059037Z","shell.execute_reply.started":"2024-10-30T08:56:58.018684Z","shell.execute_reply":"2024-10-30T08:56:58.058098Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Decision Tree Binary Classification Accuracy: 0.7520661157024794\n              precision    recall  f1-score   support\n\n    Non-Hate       0.70      0.50      0.58        42\n        Hate       0.77      0.89      0.82        79\n\n    accuracy                           0.75       121\n   macro avg       0.73      0.69      0.70       121\nweighted avg       0.75      0.75      0.74       121\n\n[CV] END svm__C=1, svm__degree=3, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.2s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END ........................................svm__C=0.01; total time=   0.1s\n[CV] END .........................................svm__C=0.1; total time=   0.1s\n[CV] END ...........................................svm__C=1; total time=   0.1s\n[CV] END ...........................................svm__C=1; total time=   0.1s\n[CV] END ..........................................svm__C=10; total time=   0.1s\n[CV] END ..........................................svm__C=10; total time=   0.1s\n[CV] END .........................................svm__C=100; total time=   0.1s\n[CV] END .........................................svm__C=0.1; total time=   0.1s\n[CV] END .........................................svm__C=0.1; total time=   0.1s\n[CV] END .........................................svm__C=0.1; total time=   0.1s\n[CV] END ..........................................svm__C=10; total time=   0.1s\n[CV] END ..........................................svm__C=10; total time=   0.1s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.2s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=1, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=2, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=scale, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=rbf, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=5000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 3); total time=   0.1s\n[CV] END ........................................svm__C=0.01; total time=   0.1s\n[CV] END .........................................svm__C=0.1; total time=   0.1s\n[CV] END ...........................................svm__C=1; total time=   0.2s\n[CV] END ..........................................svm__C=10; total time=   0.1s\n[CV] END .........................................svm__C=100; total time=   0.1s\n[CV] END .........................................svm__C=100; total time=   0.1s\n[CV] END svm__C=10, svm__degree=3, svm__gamma=auto, svm__kernel=poly, tfidf__max_features=10000, tfidf__ngram_range=(1, 2); total time=   0.1s\n[CV] END ........................................svm__C=0.01; total time=   0.1s\n[CV] END ........................................svm__C=0.01; total time=   0.1s\n[CV] END ...........................................svm__C=1; total time=   0.1s\n[CV] END ...........................................svm__C=1; total time=   0.2s\n[CV] END .........................................svm__C=100; total time=   0.1s\n[CV] END .........................................svm__C=100; total time=   0.1s\n","output_type":"stream"}],"execution_count":199},{"cell_type":"code","source":"# Define label mapping for all 5 categories\nlabel_mapping = {'N': 0, 'C': 1, 'G': 2, 'P': 3, 'R': 4}\n\n# Ensure the column name is correct\ndf['SHORT LABLE'] = df['SHORT LABLE'].map(label_mapping)\n\n# Split the dataset into training and testing sets\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(\n    df['TRANSCRIPTION'], df['SHORT LABLE'], test_size=0.2, random_state=42)\n\n# TF-IDF Vectorization\ntfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\nX_train_tfidf = tfidf_vectorizer.fit_transform(train_texts)\nX_test_tfidf = tfidf_vectorizer.transform(test_texts)\n\n# SVM Classifier\nsvm_model = SVC(kernel='linear', C=1)\nsvm_model.fit(X_train_tfidf, train_labels)\n\n# Predict and Evaluate\ntfidf_svm_preds = svm_model.predict(X_test_tfidf)\ntfidf_svm_accuracy = accuracy_score(test_labels, tfidf_svm_preds)\nprint(f\"TF-IDF + SVM Accuracy: {tfidf_svm_accuracy}\")\nprint(classification_report(test_labels, tfidf_svm_preds, target_names=label_mapping.keys()))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T08:59:37.481604Z","iopub.execute_input":"2024-10-30T08:59:37.482410Z","iopub.status.idle":"2024-10-30T08:59:37.619788Z","shell.execute_reply.started":"2024-10-30T08:59:37.482368Z","shell.execute_reply":"2024-10-30T08:59:37.618914Z"},"trusted":true},"outputs":[{"name":"stdout","text":"TF-IDF + SVM Accuracy: 0.5454545454545454\n              precision    recall  f1-score   support\n\n           N       0.50      0.88      0.64        42\n           C       0.55      0.55      0.55        22\n           G       0.64      0.39      0.49        23\n           P       0.67      0.13      0.22        15\n           R       0.75      0.32      0.44        19\n\n    accuracy                           0.55       121\n   macro avg       0.62      0.45      0.47       121\nweighted avg       0.60      0.55      0.51       121\n\n","output_type":"stream"}],"execution_count":201},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load dataset and apply label mapping for multi-class classification\ndf = pd.read_excel('/kaggle/input/dataset1/TELUGU_METADATA.xlsx')\nlabel_mapping = {'N': 0, 'C': 1, 'G': 2, 'P': 3, 'R': 4}\ndf['SHORT LABLE'] = df['SHORT LABLE'].map(label_mapping)\n\n# Split the dataset into training and testing sets\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(\n    df['TRANSCRIPTION'], df['SHORT LABLE'], test_size=0.2, random_state=42\n)\n\n# TF-IDF Vectorization\ntfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\nX_train_tfidf = tfidf_vectorizer.fit_transform(train_texts)\nX_test_tfidf = tfidf_vectorizer.transform(test_texts)\n\n# Logistic Regression Classifier\nlog_reg_model = LogisticRegression(max_iter=1000)\nlog_reg_model.fit(X_train_tfidf, train_labels)\n\n# Predict and Evaluate\ntfidf_log_reg_preds = log_reg_model.predict(X_test_tfidf)\ntfidf_log_reg_accuracy = accuracy_score(test_labels, tfidf_log_reg_preds)\nprint(f\"TF-IDF + Logistic Regression Accuracy: {tfidf_log_reg_accuracy}\")\nprint(classification_report(test_labels, tfidf_log_reg_preds, target_names=label_mapping.keys()))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T09:05:27.996076Z","iopub.execute_input":"2024-10-30T09:05:27.996812Z","iopub.status.idle":"2024-10-30T09:05:29.799853Z","shell.execute_reply.started":"2024-10-30T09:05:27.996771Z","shell.execute_reply":"2024-10-30T09:05:29.798886Z"},"trusted":true},"outputs":[{"name":"stdout","text":"TF-IDF + Logistic Regression Accuracy: 0.49586776859504134\n              precision    recall  f1-score   support\n\n           N       0.43      0.95      0.59        42\n           C       0.65      0.50      0.56        22\n           G       0.75      0.26      0.39        23\n           P       1.00      0.07      0.12        15\n           R       1.00      0.11      0.19        19\n\n    accuracy                           0.50       121\n   macro avg       0.77      0.38      0.37       121\nweighted avg       0.69      0.50      0.43       121\n\n","output_type":"stream"}],"execution_count":208},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load dataset and apply label mapping for multi-class classification\ndf = pd.read_excel('/kaggle/input/dataset1/TELUGU_METADATA.xlsx')\nlabel_mapping = {'N': 0, 'C': 1, 'G': 2, 'P': 3, 'R': 4}\ndf['SHORT LABLE'] = df['SHORT LABLE'].map(label_mapping)\n\n# Split the dataset into training and testing sets\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(\n    df['TRANSCRIPTION'], df['SHORT LABLE'], test_size=0.2, random_state=42\n)\n\n# TF-IDF Vectorization\ntfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\nX_train_tfidf = tfidf_vectorizer.fit_transform(train_texts)\nX_test_tfidf = tfidf_vectorizer.transform(test_texts)\n\n# Random Forest Classifier\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(X_train_tfidf, train_labels)\n\n# Predict and Evaluate\ntfidf_rf_preds = rf_model.predict(X_test_tfidf)\ntfidf_rf_accuracy = accuracy_score(test_labels, tfidf_rf_preds)\nprint(f\"TF-IDF + Random Forest Accuracy: {tfidf_rf_accuracy}\")\nprint(classification_report(test_labels, tfidf_rf_preds, target_names=label_mapping.keys()))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T09:05:43.462590Z","iopub.execute_input":"2024-10-30T09:05:43.462991Z","iopub.status.idle":"2024-10-30T09:05:44.147080Z","shell.execute_reply.started":"2024-10-30T09:05:43.462952Z","shell.execute_reply":"2024-10-30T09:05:44.146168Z"},"trusted":true},"outputs":[{"name":"stdout","text":"TF-IDF + Random Forest Accuracy: 0.4793388429752066\n              precision    recall  f1-score   support\n\n           N       0.65      0.74      0.69        42\n           C       0.31      0.64      0.42        22\n           G       0.38      0.35      0.36        23\n           P       0.67      0.13      0.22        15\n           R       0.75      0.16      0.26        19\n\n    accuracy                           0.48       121\n   macro avg       0.55      0.40      0.39       121\nweighted avg       0.55      0.48      0.45       121\n\n","output_type":"stream"}],"execution_count":209},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load dataset and apply label mapping for multi-class classification\ndf = pd.read_excel('/kaggle/input/dataset1/TELUGU_METADATA.xlsx')\nlabel_mapping = {'N': 0, 'C': 1, 'G': 2, 'P': 3, 'R': 4}\ndf['SHORT LABLE'] = df['SHORT LABLE'].map(label_mapping)\n\n# Split the dataset into training and testing sets\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(\n    df['TRANSCRIPTION'], df['SHORT LABLE'], test_size=0.2, random_state=42\n)\n\n# TF-IDF Vectorization\ntfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\nX_train_tfidf = tfidf_vectorizer.fit_transform(train_texts)\nX_test_tfidf = tfidf_vectorizer.transform(test_texts)\n\n# K-Nearest Neighbors Classifier\nknn_model = KNeighborsClassifier(n_neighbors=5)\nknn_model.fit(X_train_tfidf, train_labels)\n\n# Predict and Evaluate\ntfidf_knn_preds = knn_model.predict(X_test_tfidf)\ntfidf_knn_accuracy = accuracy_score(test_labels, tfidf_knn_preds)\nprint(f\"TF-IDF + K-Nearest Neighbors Accuracy: {tfidf_knn_accuracy}\")\nprint(classification_report(test_labels, tfidf_knn_preds, target_names=label_mapping.keys()))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T09:06:15.627635Z","iopub.execute_input":"2024-10-30T09:06:15.628013Z","iopub.status.idle":"2024-10-30T09:06:15.869588Z","shell.execute_reply.started":"2024-10-30T09:06:15.627980Z","shell.execute_reply":"2024-10-30T09:06:15.868651Z"},"trusted":true},"outputs":[{"name":"stdout","text":"TF-IDF + K-Nearest Neighbors Accuracy: 0.4132231404958678\n              precision    recall  f1-score   support\n\n           N       0.69      0.52      0.59        42\n           C       0.26      0.50      0.34        22\n           G       0.37      0.61      0.46        23\n           P       0.33      0.13      0.19        15\n           R       0.33      0.05      0.09        19\n\n    accuracy                           0.41       121\n   macro avg       0.40      0.36      0.34       121\nweighted avg       0.45      0.41      0.39       121\n\n","output_type":"stream"}],"execution_count":211},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load dataset and apply label mapping for multi-class classification\ndf = pd.read_excel('/kaggle/input/dataset1/TELUGU_METADATA.xlsx')\nlabel_mapping = {'N': 0, 'C': 1, 'G': 2, 'P': 3, 'R': 4}\ndf['SHORT LABLE'] = df['SHORT LABLE'].map(label_mapping)\n\n# Split the dataset into training and testing sets\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(\n    df['TRANSCRIPTION'], df['SHORT LABLE'], test_size=0.2, random_state=42\n)\n\n# TF-IDF Vectorization\ntfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\nX_train_tfidf = tfidf_vectorizer.fit_transform(train_texts)\nX_test_tfidf = tfidf_vectorizer.transform(test_texts)\n\n# Decision Tree Classifier\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(X_train_tfidf, train_labels)\n\n# Predict and Evaluate\ntfidf_dt_preds = dt_model.predict(X_test_tfidf)\ntfidf_dt_accuracy = accuracy_score(test_labels, tfidf_dt_preds)\nprint(f\"TF-IDF + Decision Tree Accuracy: {tfidf_dt_accuracy}\")\nprint(classification_report(test_labels, tfidf_dt_preds, target_names=label_mapping.keys()))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T09:06:41.364273Z","iopub.execute_input":"2024-10-30T09:06:41.364721Z","iopub.status.idle":"2024-10-30T09:06:41.636650Z","shell.execute_reply.started":"2024-10-30T09:06:41.364680Z","shell.execute_reply":"2024-10-30T09:06:41.635679Z"},"trusted":true},"outputs":[{"name":"stdout","text":"TF-IDF + Decision Tree Accuracy: 0.32231404958677684\n              precision    recall  f1-score   support\n\n           N       0.52      0.36      0.42        42\n           C       0.25      0.55      0.34        22\n           G       0.35      0.30      0.33        23\n           P       0.07      0.07      0.07        15\n           R       0.40      0.21      0.28        19\n\n    accuracy                           0.32       121\n   macro avg       0.32      0.30      0.29       121\nweighted avg       0.36      0.32      0.32       121\n\n","output_type":"stream"}],"execution_count":212},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}